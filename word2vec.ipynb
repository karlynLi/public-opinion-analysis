{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyvis\n",
    "import random\n",
    "import networkx as nx\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(*args)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 編碼解決方法  \n",
    "import _locale\n",
    "_locale._getdefaultlocale = (lambda *args: ['en_US', 'utf8'])\n",
    "_locale._getdefaultlocale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1</th>\n",
       "      <th>item2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nissan</td>\n",
       "      <td>nnissan</td>\n",
       "      <td>0.667420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nissan</td>\n",
       "      <td>nismo</td>\n",
       "      <td>0.574859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nissan</td>\n",
       "      <td>今日</td>\n",
       "      <td>0.560769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nissan</td>\n",
       "      <td>裕隆日產</td>\n",
       "      <td>0.556396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nissan</td>\n",
       "      <td>主角</td>\n",
       "      <td>0.541733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>照樣</td>\n",
       "      <td>0.711645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>好意思</td>\n",
       "      <td>0.709959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>中共</td>\n",
       "      <td>0.707242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>看不起</td>\n",
       "      <td>0.702805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>偷料</td>\n",
       "      <td>0.701735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item1    item2  correlation\n",
       "0     nissan  nnissan     0.667420\n",
       "1     nissan    nismo     0.574859\n",
       "2     nissan       今日     0.560769\n",
       "3     nissan     裕隆日產     0.556396\n",
       "4     nissan       主角     0.541733\n",
       "...      ...      ...          ...\n",
       "1995     台灣人       照樣     0.711645\n",
       "1996     台灣人      好意思     0.709959\n",
       "1997     台灣人       中共     0.707242\n",
       "1998     台灣人      看不起     0.702805\n",
       "1999     台灣人       偷料     0.701735\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./rawData/nissan_correlation.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df['item1'].dtype)\n",
    "print(df['item2'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1</th>\n",
       "      <th>item2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nissan</td>\n",
       "      <td>nnissan</td>\n",
       "      <td>0.667420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nissan</td>\n",
       "      <td>nismo</td>\n",
       "      <td>0.574859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nissan</td>\n",
       "      <td>今日</td>\n",
       "      <td>0.560769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nissan</td>\n",
       "      <td>裕隆日產</td>\n",
       "      <td>0.556396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nissan</td>\n",
       "      <td>主角</td>\n",
       "      <td>0.541733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>照樣</td>\n",
       "      <td>0.711645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>好意思</td>\n",
       "      <td>0.709959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>中共</td>\n",
       "      <td>0.707242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>看不起</td>\n",
       "      <td>0.702805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>偷料</td>\n",
       "      <td>0.701735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item1    item2  correlation\n",
       "0     nissan  nnissan     0.667420\n",
       "1     nissan    nismo     0.574859\n",
       "2     nissan       今日     0.560769\n",
       "3     nissan     裕隆日產     0.556396\n",
       "4     nissan       主角     0.541733\n",
       "...      ...      ...          ...\n",
       "1995     台灣人       照樣     0.711645\n",
       "1996     台灣人      好意思     0.709959\n",
       "1997     台灣人       中共     0.707242\n",
       "1998     台灣人      看不起     0.702805\n",
       "1999     台灣人       偷料     0.701735\n",
       "\n",
       "[1999 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.copy()\n",
    "data = data[~data.item1.isna()]\n",
    "data = data[~data.item2.isna()]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1</th>\n",
       "      <th>item2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>業務</td>\n",
       "      <td>業代</td>\n",
       "      <td>0.745061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>空間</td>\n",
       "      <td>寬敞</td>\n",
       "      <td>0.704260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>油電</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>0.702189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>focus</td>\n",
       "      <td>active</td>\n",
       "      <td>0.729345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>後座</td>\n",
       "      <td>膝部</td>\n",
       "      <td>0.739037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>照樣</td>\n",
       "      <td>0.711645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>好意思</td>\n",
       "      <td>0.709959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>中共</td>\n",
       "      <td>0.707242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>看不起</td>\n",
       "      <td>0.702805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>偷料</td>\n",
       "      <td>0.701735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      item1   item2  correlation\n",
       "80       業務      業代     0.745061\n",
       "90       空間      寬敞     0.704260\n",
       "120      油電  hybrid     0.702189\n",
       "240   focus  active     0.729345\n",
       "401      後座      膝部     0.739037\n",
       "...     ...     ...          ...\n",
       "1995    台灣人      照樣     0.711645\n",
       "1996    台灣人     好意思     0.709959\n",
       "1997    台灣人      中共     0.707242\n",
       "1998    台灣人     看不起     0.702805\n",
       "1999    台灣人      偷料     0.701735\n",
       "\n",
       "[232 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[(data['correlation'] <= 0.75) & (data['correlation'] > 0.7)]\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算 adjency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 291)\n"
     ]
    }
   ],
   "source": [
    "pers = np.unique(data[['item1', 'item2']])\n",
    "mat = pd.pivot_table(data,index = 'item1', columns = 'item2' ,values='correlation').fillna(0)\\\n",
    "  .reindex(columns=pers, index=pers, fill_value=0).to_numpy() # 有向圖\n",
    "print(mat.shape)\n",
    "tri = (np.tril(mat,-1).T + np.triu(mat,1))\n",
    "mat_s = tri+tri.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "繪製網路圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_color():\n",
    "  r = lambda: random.randint(0,255)\n",
    "  return '#%02X%02X%02X' % (r(),r(),r())\n",
    "\n",
    "# input matrix, output graph\n",
    "def matPresentGraph(mat:np.array,node_id:list,node_value:list = None,edge_color=None):\n",
    "\n",
    "  if edge_color == None:\n",
    "    edge_color = random_color()\n",
    "  edge_color = random_color()\n",
    "  if node_value == None:\n",
    "    node_value = [1 for i in range(len(node_id))]\n",
    "\n",
    "  # cdn_resource : 指定網路圖的CDN資源  \n",
    "  net = Network(notebook=True, cdn_resources='in_line')\n",
    "\n",
    "  titles_list = []\n",
    "  for i in zip(node_id):\n",
    "    titles_list.append(str(i))\n",
    "\n",
    "  net.add_nodes(\n",
    "      nodes = node_id,\n",
    "      value = node_value,\n",
    "      label = node_id,\n",
    "      title = titles_list\n",
    "  )\n",
    "\n",
    "  for row in range(len(node_id)):\n",
    "    for col in range(len(node_id)):\n",
    "      if mat[row][col]>0.:\n",
    "        net.add_edge(\n",
    "            node_id[row],node_id[col],width = mat[row][col],color = edge_color,title = mat[row][col]\n",
    "        )\n",
    "\n",
    "  # 計算layout，產生更易讀的網路圖 (使節點散開、避免節點重疊)\n",
    "  net.repulsion()\n",
    "  return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n",
      "291\n",
      "291\n",
      "./nissan_w2v.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"./nissan_w2v.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x23eb2a532e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = matPresentGraph(mat = mat,node_id = pers)\n",
    "\n",
    "net.show(\"./nissan_w2v.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>system_id</th>\n",
       "      <th>artTitle</th>\n",
       "      <th>artDate</th>\n",
       "      <th>artPoster</th>\n",
       "      <th>artCatagory</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH</td>\n",
       "      <td>2020/12/1 00:09</td>\n",
       "      <td>city0504</td>\n",
       "      <td>car</td>\n",
       "      <td>['Corolla', 'Cross', '當紅', '炸子雞', 'NISSAN', 'K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH</td>\n",
       "      <td>2020/12/1 00:09</td>\n",
       "      <td>city0504</td>\n",
       "      <td>car</td>\n",
       "      <td>['一網打盡', '不同', '消費', '需求', 'VW', 'TRocT', 'Cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH</td>\n",
       "      <td>2020/12/1 00:09</td>\n",
       "      <td>city0504</td>\n",
       "      <td>car</td>\n",
       "      <td>['尺碼', '規配', '迥異', '獨立', '車型', '吸引', '不同', '個性...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH</td>\n",
       "      <td>2020/12/1 00:09</td>\n",
       "      <td>city0504</td>\n",
       "      <td>car</td>\n",
       "      <td>['PEUGEOT', '3008', '單是', '引進', '國內', '車款', '選擇']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH</td>\n",
       "      <td>2020/12/1 00:09</td>\n",
       "      <td>city0504</td>\n",
       "      <td>car</td>\n",
       "      <td>['引擎動力', '汽油', '柴油']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71827</th>\n",
       "      <td>2324</td>\n",
       "      <td>2325</td>\n",
       "      <td>[售車]自售NISSANTEANAJ3120052.0</td>\n",
       "      <td>2023/1/26 17:42</td>\n",
       "      <td>efs92e01</td>\n",
       "      <td>CarShop</td>\n",
       "      <td>['電話', '0919911030LINE', '電話', '號碼', '聯繫']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71828</th>\n",
       "      <td>2324</td>\n",
       "      <td>2325</td>\n",
       "      <td>[售車]自售NISSANTEANAJ3120052.0</td>\n",
       "      <td>2023/1/26 17:42</td>\n",
       "      <td>efs92e01</td>\n",
       "      <td>CarShop</td>\n",
       "      <td>['不要', '半夜', '打給']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71829</th>\n",
       "      <td>2325</td>\n",
       "      <td>2326</td>\n",
       "      <td>售Kicks原廠避光墊</td>\n",
       "      <td>2023/1/30 21:44</td>\n",
       "      <td>tingiy</td>\n",
       "      <td>CarShop</td>\n",
       "      <td>['物品', '名稱', 'Nissan', 'kicks', '避光', '物品', '狀...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71830</th>\n",
       "      <td>2325</td>\n",
       "      <td>2326</td>\n",
       "      <td>售Kicks原廠避光墊</td>\n",
       "      <td>2023/1/30 21:44</td>\n",
       "      <td>tingiy</td>\n",
       "      <td>CarShop</td>\n",
       "      <td>['中壢', '車站', '輻射', '向外', '15', '公里', '宅配', '欲售...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71831</th>\n",
       "      <td>2325</td>\n",
       "      <td>2326</td>\n",
       "      <td>售Kicks原廠避光墊</td>\n",
       "      <td>2023/1/30 21:44</td>\n",
       "      <td>tingiy</td>\n",
       "      <td>CarShop</td>\n",
       "      <td>['假日', '討論', '分類', '不見了', 'QQ']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71832 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  system_id                         artTitle   \n",
       "0               0          1  [新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH  \\\n",
       "1               0          1  [新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH   \n",
       "2               0          1  [新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH   \n",
       "3               0          1  [新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH   \n",
       "4               0          1  [新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH   \n",
       "...           ...        ...                              ...   \n",
       "71827        2324       2325      [售車]自售NISSANTEANAJ3120052.0   \n",
       "71828        2324       2325      [售車]自售NISSANTEANAJ3120052.0   \n",
       "71829        2325       2326                      售Kicks原廠避光墊   \n",
       "71830        2325       2326                      售Kicks原廠避光墊   \n",
       "71831        2325       2326                      售Kicks原廠避光墊   \n",
       "\n",
       "               artDate artPoster artCatagory   \n",
       "0      2020/12/1 00:09  city0504         car  \\\n",
       "1      2020/12/1 00:09  city0504         car   \n",
       "2      2020/12/1 00:09  city0504         car   \n",
       "3      2020/12/1 00:09  city0504         car   \n",
       "4      2020/12/1 00:09  city0504         car   \n",
       "...                ...       ...         ...   \n",
       "71827  2023/1/26 17:42  efs92e01     CarShop   \n",
       "71828  2023/1/26 17:42  efs92e01     CarShop   \n",
       "71829  2023/1/30 21:44    tingiy     CarShop   \n",
       "71830  2023/1/30 21:44    tingiy     CarShop   \n",
       "71831  2023/1/30 21:44    tingiy     CarShop   \n",
       "\n",
       "                                                    word  \n",
       "0      ['Corolla', 'Cross', '當紅', '炸子雞', 'NISSAN', 'K...  \n",
       "1      ['一網打盡', '不同', '消費', '需求', 'VW', 'TRocT', 'Cro...  \n",
       "2      ['尺碼', '規配', '迥異', '獨立', '車型', '吸引', '不同', '個性...  \n",
       "3      ['PEUGEOT', '3008', '單是', '引進', '國內', '車款', '選擇']  \n",
       "4                                   ['引擎動力', '汽油', '柴油']  \n",
       "...                                                  ...  \n",
       "71827         ['電話', '0919911030LINE', '電話', '號碼', '聯繫']  \n",
       "71828                                 ['不要', '半夜', '打給']  \n",
       "71829  ['物品', '名稱', 'Nissan', 'kicks', '避光', '物品', '狀...  \n",
       "71830  ['中壢', '車站', '輻射', '向外', '15', '公里', '宅配', '欲售...  \n",
       "71831                    ['假日', '討論', '分類', '不見了', 'QQ']  \n",
       "\n",
       "[71832 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaData = pd.read_csv('./output/nissan_ptt_clean.csv')\n",
    "metaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from gensim.models.phrases import Phrases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m sents \u001b[39m=\u001b[39m metaData[\u001b[39m'\u001b[39m\u001b[39mword\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto_list()\n\u001b[0;32m      2\u001b[0m bigrams \u001b[39m=\u001b[39m Phrases(sents,min_count\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, threshold\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m bigram_phrasers \u001b[39m=\u001b[39m Phrases(bigrams)\n\u001b[0;32m      4\u001b[0m metaData[\u001b[39m'\u001b[39m\u001b[39mword_list_bigrams\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(bigram_phrasers[sents])\n\u001b[0;32m      6\u001b[0m metaData\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\s2568\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\phrases.py:569\u001b[0m, in \u001b[0;36mPhrases.__init__\u001b[1;34m(self, sentences, min_count, threshold, max_vocab_size, delimiter, progress_per, scoring, connector_words)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[39mif\u001b[39;00m sentences \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    568\u001b[0m     start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 569\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_vocab(sentences)\n\u001b[0;32m    570\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_lifecycle_event(\u001b[39m\"\u001b[39m\u001b[39mcreated\u001b[39m\u001b[39m\"\u001b[39m, msg\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbuilt \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime()\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\s2568\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\phrases.py:648\u001b[0m, in \u001b[0;36mPhrases.add_vocab\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Update model parameters with new `sentences`.\u001b[39;00m\n\u001b[0;32m    615\u001b[0m \n\u001b[0;32m    616\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    641\u001b[0m \n\u001b[0;32m    642\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[39m# Uses a separate vocab to collect the token counts from `sentences`.\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[39m# This consumes more RAM than merging new sentences into `self.vocab`\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[39m# directly, but gives the new sentences a fighting chance to collect\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[39m# sufficient counts, before being pruned out by the (large) accumulated\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[39m# counts collected in previous learn_vocab runs.\u001b[39;00m\n\u001b[1;32m--> 648\u001b[0m min_reduce, vocab, total_words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learn_vocab(\n\u001b[0;32m    649\u001b[0m     sentences, max_vocab_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_vocab_size, delimiter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdelimiter,\n\u001b[0;32m    650\u001b[0m     progress_per\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprogress_per, connector_words\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnector_words,\n\u001b[0;32m    651\u001b[0m )\n\u001b[0;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorpus_word_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m total_words\n\u001b[0;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab:\n",
      "File \u001b[1;32mc:\\Users\\s2568\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\phrases.py:584\u001b[0m, in \u001b[0;36mPhrases._learn_vocab\u001b[1;34m(sentences, max_vocab_size, delimiter, connector_words, progress_per)\u001b[0m\n\u001b[0;32m    582\u001b[0m vocab \u001b[39m=\u001b[39m {}\n\u001b[0;32m    583\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mcollecting all words and their counts\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 584\u001b[0m \u001b[39mfor\u001b[39;00m sentence_no, sentence \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sentences):\n\u001b[0;32m    585\u001b[0m     \u001b[39mif\u001b[39;00m sentence_no \u001b[39m%\u001b[39m progress_per \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    586\u001b[0m         logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    587\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPROGRESS: at sentence #\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m, processed \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m words and \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m word types\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    588\u001b[0m             sentence_no, total_words, \u001b[39mlen\u001b[39m(vocab),\n\u001b[0;32m    589\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\s2568\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\phrases.py:296\u001b[0m, in \u001b[0;36m_PhrasesTransformation.__getitem__\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, sentence):\n\u001b[0;32m    277\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"Convert the input sequence of tokens ``sentence`` into a sequence of tokens where adjacent\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[39m        tokens are replaced by a single token if they form a bigram collocation.\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    294\u001b[0m \n\u001b[0;32m    295\u001b[0m \u001b[39ms        \"\"\"\u001b[39;00m\n\u001b[1;32m--> 296\u001b[0m         is_single, sentence \u001b[39m=\u001b[39m _is_single(sentence)\n\u001b[0;32m    297\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_single:\n\u001b[0;32m    298\u001b[0m             \u001b[39m# If the input is an entire corpus (rather than a single sentence),\u001b[39;00m\n\u001b[0;32m    299\u001b[0m             \u001b[39m# return an iterable stream.\u001b[39;00m\n\u001b[0;32m    300\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(sentence)\n",
      "File \u001b[1;32mc:\\Users\\s2568\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\phrases.py:188\u001b[0m, in \u001b[0;36m_is_single\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_is_single\u001b[39m(obj):\n\u001b[0;32m    171\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check whether `obj` is a single document or an entire corpus.\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \n\u001b[0;32m    173\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \n\u001b[0;32m    187\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m     obj_iter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39;49m(obj)\n\u001b[0;32m    189\u001b[0m     temp_iter \u001b[39m=\u001b[39m obj_iter\n\u001b[0;32m    190\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "sents = metaData['word'].to_list()\n",
    "bigrams = Phrases(sents, min_count=1, threshold=1000)\n",
    "bigram_phrasers = Phrases(bigrams)\n",
    "metaData['word_list_bigrams'] = list(bigram_phrasers[sents])\n",
    "\n",
    "metaData.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
