{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 有望客字詞關聯圖 - Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "from gensim import models\n",
    "import ast\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/sentiment/nissan_clean_data.csv')\n",
    "df = df[['system_id', 'words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_id</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>新聞 小休 熱鬧 好玩 PEUGEOT300815LBlueH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>情報 2020 11 月份 臺灣汽車 市場 銷售 報告 新增 小七車</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>新聞 豐田 PremioAllionPriusAlpha 明年 停產 標題 房車 轎式 MP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>缺點 選車 重點 new juke 試駕 影片 慢慢 釋出 8891 影片 結尾 依舊 提出</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>菜單 NissanAllNEWSentra 尊爵型 Nissan2020All New Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>2459</td>\n",
       "      <td>購車 休旅車 HondaToyotaLexusNissan SUV 1800cc 以內 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>2461</td>\n",
       "      <td>售車 Nissan2013BIGTIIDA5 NISSAN 20131 BIG TIIDA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>2462</td>\n",
       "      <td>售車 Nissankicks 智行 旗艦版 2019 2019 06 1498 顏色 排檔 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>2463</td>\n",
       "      <td>售車 自售 NISSANTEANAJ31200520 2005 06 J31 TEANA 顏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>2464</td>\n",
       "      <td>Kicks 原廠 避光 物品 名稱 Nissan kicks 避光 物品 狀況 新車 替換 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2079 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      system_id                                              words\n",
       "0             1                    新聞 小休 熱鬧 好玩 PEUGEOT300815LBlueH\n",
       "1             2                 情報 2020 11 月份 臺灣汽車 市場 銷售 報告 新增 小七車\n",
       "2             3  新聞 豐田 PremioAllionPriusAlpha 明年 停產 標題 房車 轎式 MP...\n",
       "3             4     缺點 選車 重點 new juke 試駕 影片 慢慢 釋出 8891 影片 結尾 依舊 提出\n",
       "4             5  菜單 NissanAllNEWSentra 尊爵型 Nissan2020All New Se...\n",
       "...         ...                                                ...\n",
       "2074       2459  購車 休旅車 HondaToyotaLexusNissan SUV 1800cc 以內 20...\n",
       "2075       2461  售車 Nissan2013BIGTIIDA5 NISSAN 20131 BIG TIIDA ...\n",
       "2076       2462  售車 Nissankicks 智行 旗艦版 2019 2019 06 1498 顏色 排檔 ...\n",
       "2077       2463  售車 自售 NISSANTEANAJ31200520 2005 06 J31 TEANA 顏...\n",
       "2078       2464  Kicks 原廠 避光 物品 名稱 Nissan kicks 避光 物品 狀況 新車 替換 ...\n",
       "\n",
       "[2079 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['words'] = df['words'].apply(lambda x: ast.literal_eval(x))\n",
    "df['words'] = df['words'].apply(lambda x: ' '.join(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/word2vec/nissan_w2v.txt', sep='\\t', index=False, header=True, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('./data/word2vec/nissan_w2v.txt', 'w', encoding='utf-8')\n",
    "for index, row in df.iterrows():\n",
    "    output.write(row['words'] + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取已斷詞的資料集\n",
    "sentences = []\n",
    "with open('./data/word2vec/nissan_w2v.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # 假設每行是以空白分隔的詞彙\n",
    "        words = line.strip().split()\n",
    "        sentences.append(words)\n",
    "model = word2vec.Word2Vec(sentences, sg=1, window=6, min_count=30, workers=4, vector_size=250)\n",
    "\n",
    "# 保存模型，供日後使用\n",
    "model.save(\"./data/word2vec/nissan_word2vec.model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看相關詞彙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOCUS 0.8920780420303345\n",
      "焦點 0.880046010017395\n",
      "不輸 0.8784715533256531\n",
      "camry 0.8551652431488037\n",
      "這代 0.8547437787055969\n",
      "沒力 0.8538542985916138\n",
      "佛心 0.8529285192489624\n",
      "哪台 0.8526982069015503\n",
      "140 0.8512624502182007\n",
      "仙草 0.8394905924797058\n"
     ]
    }
   ],
   "source": [
    "# 可以使用model.wv.most_similar()來查詢相似詞彙\n",
    "similar_words = model.wv.most_similar('altis', topn=10)\n",
    "for word, similarity in similar_words:\n",
    "    print(word, similarity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依據資料集的詞頻去找相關字詞"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "詞頻計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將所有的詞彙合併為一個大字串\n",
    "all_words = ' '.join(df['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>問題</td>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>空間</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>價格</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>業務</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>原廠</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22673</th>\n",
       "      <td>附件</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22672</th>\n",
       "      <td>低額</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22670</th>\n",
       "      <td>樂勝馬</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22668</th>\n",
       "      <td>威根</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44743</th>\n",
       "      <td>元站</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  freq\n",
       "474     問題  1497\n",
       "317     空間  1019\n",
       "312     價格   851\n",
       "97      業務   812\n",
       "61      原廠   776\n",
       "...    ...   ...\n",
       "22673   附件     1\n",
       "22672   低額     1\n",
       "22670  樂勝馬     1\n",
       "22668   威根     1\n",
       "44743   元站     1\n",
       "\n",
       "[44744 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用Counter計算詞頻\n",
    "word_counts = Counter(all_words.split())\n",
    "\n",
    "count_df = pd.DataFrame.from_dict(word_counts, orient='index').reset_index()\n",
    "count_df.columns = ['word', 'freq']\n",
    "count_df.sort_values(ascending=False, by='freq',inplace=True)\n",
    "count_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立字詞correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1</th>\n",
       "      <th>item2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [item1, item2, correlation]\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_most_correlation = pd.DataFrame(columns=['item1', 'item2', 'correlation'])\n",
    "df_most_correlation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定義相關字詞函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_similar_word(word, n):\n",
    "    similar_words = model.wv.most_similar(word, topn=n)\n",
    "    return similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m topn:\n\u001b[0;32m      8\u001b[0m     tmp \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mitem1\u001b[39m\u001b[39m'\u001b[39m: row[\u001b[39m'\u001b[39m\u001b[39mword\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mitem2\u001b[39m\u001b[39m'\u001b[39m: item[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mcorrelation\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mstr\u001b[39m(item[\u001b[39m1\u001b[39m])}\n\u001b[1;32m----> 9\u001b[0m     df_most_correlation \u001b[39m=\u001b[39m df_most_correlation\u001b[39m.\u001b[39;49mappend(tmp, ignore_index \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "for index, row in count_df.iterrows():\n",
    "    try:\n",
    "        topn = get_top_similar_word(row['word'], 10)\n",
    "    except:\n",
    "        print(row['word'])\n",
    "        continue\n",
    "    for item in topn:\n",
    "        tmp = {'item1': row['word'], 'item2': item[0], 'correlation': str(item[1])}\n",
    "        df_most_correlation = df_most_correlation.append(tmp, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1</th>\n",
       "      <th>item2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nissan</td>\n",
       "      <td>nnissan</td>\n",
       "      <td>0.667420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nissan</td>\n",
       "      <td>nismo</td>\n",
       "      <td>0.574859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nissan</td>\n",
       "      <td>今日</td>\n",
       "      <td>0.560769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nissan</td>\n",
       "      <td>裕隆日產</td>\n",
       "      <td>0.556396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nissan</td>\n",
       "      <td>主角</td>\n",
       "      <td>0.541733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>照樣</td>\n",
       "      <td>0.711645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>好意思</td>\n",
       "      <td>0.709959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>中共</td>\n",
       "      <td>0.707242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>看不起</td>\n",
       "      <td>0.702805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>偷料</td>\n",
       "      <td>0.701735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item1    item2  correlation\n",
       "0     nissan  nnissan     0.667420\n",
       "1     nissan    nismo     0.574859\n",
       "2     nissan       今日     0.560769\n",
       "3     nissan     裕隆日產     0.556396\n",
       "4     nissan       主角     0.541733\n",
       "...      ...      ...          ...\n",
       "1995     台灣人       照樣     0.711645\n",
       "1996     台灣人      好意思     0.709959\n",
       "1997     台灣人       中共     0.707242\n",
       "1998     台灣人      看不起     0.702805\n",
       "1999     台灣人       偷料     0.701735\n",
       "\n",
       "[1999 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.copy()\n",
    "data = data[~data.item1.isna()]\n",
    "data = data[~data.item2.isna()]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1</th>\n",
       "      <th>item2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>業務</td>\n",
       "      <td>業代</td>\n",
       "      <td>0.745061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>空間</td>\n",
       "      <td>寬敞</td>\n",
       "      <td>0.704260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>油電</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>0.702189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>focus</td>\n",
       "      <td>active</td>\n",
       "      <td>0.729345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>後座</td>\n",
       "      <td>膝部</td>\n",
       "      <td>0.739037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>照樣</td>\n",
       "      <td>0.711645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>好意思</td>\n",
       "      <td>0.709959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>中共</td>\n",
       "      <td>0.707242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>看不起</td>\n",
       "      <td>0.702805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>台灣人</td>\n",
       "      <td>偷料</td>\n",
       "      <td>0.701735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      item1   item2  correlation\n",
       "80       業務      業代     0.745061\n",
       "90       空間      寬敞     0.704260\n",
       "120      油電  hybrid     0.702189\n",
       "240   focus  active     0.729345\n",
       "401      後座      膝部     0.739037\n",
       "...     ...     ...          ...\n",
       "1995    台灣人      照樣     0.711645\n",
       "1996    台灣人     好意思     0.709959\n",
       "1997    台灣人      中共     0.707242\n",
       "1998    台灣人     看不起     0.702805\n",
       "1999    台灣人      偷料     0.701735\n",
       "\n",
       "[232 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[(data['correlation'] <= 0.75) & (data['correlation'] > 0.7)]\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算 adjency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 291)\n"
     ]
    }
   ],
   "source": [
    "pers = np.unique(data[['item1', 'item2']])\n",
    "mat = pd.pivot_table(data,index = 'item1', columns = 'item2' ,values='correlation').fillna(0)\\\n",
    "  .reindex(columns=pers, index=pers, fill_value=0).to_numpy() # 有向圖\n",
    "print(mat.shape)\n",
    "tri = (np.tril(mat,-1).T + np.triu(mat,1))\n",
    "mat_s = tri+tri.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "繪製網路圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_color():\n",
    "  r = lambda: random.randint(0,255)\n",
    "  return '#%02X%02X%02X' % (r(),r(),r())\n",
    "\n",
    "# input matrix, output graph\n",
    "def matPresentGraph(mat:np.array,node_id:list,node_value:list = None,edge_color=None):\n",
    "\n",
    "  if edge_color == None:\n",
    "    edge_color = random_color()\n",
    "  edge_color = random_color()\n",
    "  if node_value == None:\n",
    "    node_value = [1 for i in range(len(node_id))]\n",
    "\n",
    "  # cdn_resource : 指定網路圖的CDN資源  \n",
    "  net = Network(notebook=True, cdn_resources='in_line')\n",
    "\n",
    "  titles_list = []\n",
    "  for i in zip(node_id):\n",
    "    titles_list.append(str(i))\n",
    "\n",
    "  net.add_nodes(\n",
    "      nodes = node_id,\n",
    "      value = node_value,\n",
    "      label = node_id,\n",
    "      title = titles_list\n",
    "  )\n",
    "\n",
    "  for row in range(len(node_id)):\n",
    "    for col in range(len(node_id)):\n",
    "      if mat[row][col]>0.:\n",
    "        net.add_edge(\n",
    "            node_id[row],node_id[col],width = mat[row][col],color = edge_color,title = mat[row][col]\n",
    "        )\n",
    "\n",
    "  # 計算layout，產生更易讀的網路圖 (使節點散開、避免節點重疊)\n",
    "  net.repulsion()\n",
    "  return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n",
      "291\n",
      "291\n",
      "./nissan_w2v.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"./nissan_w2v.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x23eb2a532e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = matPresentGraph(mat = mat,node_id = pers)\n",
    "\n",
    "net.show(\"./nissan_w2v.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>system_id</th>\n",
       "      <th>artTitle</th>\n",
       "      <th>artDate</th>\n",
       "      <th>artPoster</th>\n",
       "      <th>artCatagory</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH</td>\n",
       "      <td>2020/12/1 00:09</td>\n",
       "      <td>city0504</td>\n",
       "      <td>car</td>\n",
       "      <td>['Corolla', 'Cross', '當紅', '炸子雞', 'NISSAN', 'K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH</td>\n",
       "      <td>2020/12/1 00:09</td>\n",
       "      <td>city0504</td>\n",
       "      <td>car</td>\n",
       "      <td>['一網打盡', '不同', '消費', '需求', 'VW', 'TRocT', 'Cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH</td>\n",
       "      <td>2020/12/1 00:09</td>\n",
       "      <td>city0504</td>\n",
       "      <td>car</td>\n",
       "      <td>['尺碼', '規配', '迥異', '獨立', '車型', '吸引', '不同', '個性...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH</td>\n",
       "      <td>2020/12/1 00:09</td>\n",
       "      <td>city0504</td>\n",
       "      <td>car</td>\n",
       "      <td>['PEUGEOT', '3008', '單是', '引進', '國內', '車款', '選擇']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH</td>\n",
       "      <td>2020/12/1 00:09</td>\n",
       "      <td>city0504</td>\n",
       "      <td>car</td>\n",
       "      <td>['引擎動力', '汽油', '柴油']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71827</th>\n",
       "      <td>2324</td>\n",
       "      <td>2325</td>\n",
       "      <td>[售車]自售NISSANTEANAJ3120052.0</td>\n",
       "      <td>2023/1/26 17:42</td>\n",
       "      <td>efs92e01</td>\n",
       "      <td>CarShop</td>\n",
       "      <td>['電話', '0919911030LINE', '電話', '號碼', '聯繫']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71828</th>\n",
       "      <td>2324</td>\n",
       "      <td>2325</td>\n",
       "      <td>[售車]自售NISSANTEANAJ3120052.0</td>\n",
       "      <td>2023/1/26 17:42</td>\n",
       "      <td>efs92e01</td>\n",
       "      <td>CarShop</td>\n",
       "      <td>['不要', '半夜', '打給']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71829</th>\n",
       "      <td>2325</td>\n",
       "      <td>2326</td>\n",
       "      <td>售Kicks原廠避光墊</td>\n",
       "      <td>2023/1/30 21:44</td>\n",
       "      <td>tingiy</td>\n",
       "      <td>CarShop</td>\n",
       "      <td>['物品', '名稱', 'Nissan', 'kicks', '避光', '物品', '狀...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71830</th>\n",
       "      <td>2325</td>\n",
       "      <td>2326</td>\n",
       "      <td>售Kicks原廠避光墊</td>\n",
       "      <td>2023/1/30 21:44</td>\n",
       "      <td>tingiy</td>\n",
       "      <td>CarShop</td>\n",
       "      <td>['中壢', '車站', '輻射', '向外', '15', '公里', '宅配', '欲售...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71831</th>\n",
       "      <td>2325</td>\n",
       "      <td>2326</td>\n",
       "      <td>售Kicks原廠避光墊</td>\n",
       "      <td>2023/1/30 21:44</td>\n",
       "      <td>tingiy</td>\n",
       "      <td>CarShop</td>\n",
       "      <td>['假日', '討論', '分類', '不見了', 'QQ']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71832 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  system_id                         artTitle   \n",
       "0               0          1  [新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH  \\\n",
       "1               0          1  [新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH   \n",
       "2               0          1  [新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH   \n",
       "3               0          1  [新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH   \n",
       "4               0          1  [新聞]小休旅熱鬧好玩PEUGEOT30081.5LBlueH   \n",
       "...           ...        ...                              ...   \n",
       "71827        2324       2325      [售車]自售NISSANTEANAJ3120052.0   \n",
       "71828        2324       2325      [售車]自售NISSANTEANAJ3120052.0   \n",
       "71829        2325       2326                      售Kicks原廠避光墊   \n",
       "71830        2325       2326                      售Kicks原廠避光墊   \n",
       "71831        2325       2326                      售Kicks原廠避光墊   \n",
       "\n",
       "               artDate artPoster artCatagory   \n",
       "0      2020/12/1 00:09  city0504         car  \\\n",
       "1      2020/12/1 00:09  city0504         car   \n",
       "2      2020/12/1 00:09  city0504         car   \n",
       "3      2020/12/1 00:09  city0504         car   \n",
       "4      2020/12/1 00:09  city0504         car   \n",
       "...                ...       ...         ...   \n",
       "71827  2023/1/26 17:42  efs92e01     CarShop   \n",
       "71828  2023/1/26 17:42  efs92e01     CarShop   \n",
       "71829  2023/1/30 21:44    tingiy     CarShop   \n",
       "71830  2023/1/30 21:44    tingiy     CarShop   \n",
       "71831  2023/1/30 21:44    tingiy     CarShop   \n",
       "\n",
       "                                                    word  \n",
       "0      ['Corolla', 'Cross', '當紅', '炸子雞', 'NISSAN', 'K...  \n",
       "1      ['一網打盡', '不同', '消費', '需求', 'VW', 'TRocT', 'Cro...  \n",
       "2      ['尺碼', '規配', '迥異', '獨立', '車型', '吸引', '不同', '個性...  \n",
       "3      ['PEUGEOT', '3008', '單是', '引進', '國內', '車款', '選擇']  \n",
       "4                                   ['引擎動力', '汽油', '柴油']  \n",
       "...                                                  ...  \n",
       "71827         ['電話', '0919911030LINE', '電話', '號碼', '聯繫']  \n",
       "71828                                 ['不要', '半夜', '打給']  \n",
       "71829  ['物品', '名稱', 'Nissan', 'kicks', '避光', '物品', '狀...  \n",
       "71830  ['中壢', '車站', '輻射', '向外', '15', '公里', '宅配', '欲售...  \n",
       "71831                    ['假日', '討論', '分類', '不見了', 'QQ']  \n",
       "\n",
       "[71832 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaData = pd.read_csv('./output/nissan_ptt_clean.csv')\n",
    "metaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from gensim.models.phrases import Phrases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m sents \u001b[39m=\u001b[39m metaData[\u001b[39m'\u001b[39m\u001b[39mword\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto_list()\n\u001b[0;32m      2\u001b[0m bigrams \u001b[39m=\u001b[39m Phrases(sents,min_count\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, threshold\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m bigram_phrasers \u001b[39m=\u001b[39m Phrases(bigrams)\n\u001b[0;32m      4\u001b[0m metaData[\u001b[39m'\u001b[39m\u001b[39mword_list_bigrams\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(bigram_phrasers[sents])\n\u001b[0;32m      6\u001b[0m metaData\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\s2568\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\phrases.py:569\u001b[0m, in \u001b[0;36mPhrases.__init__\u001b[1;34m(self, sentences, min_count, threshold, max_vocab_size, delimiter, progress_per, scoring, connector_words)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[39mif\u001b[39;00m sentences \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    568\u001b[0m     start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 569\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_vocab(sentences)\n\u001b[0;32m    570\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_lifecycle_event(\u001b[39m\"\u001b[39m\u001b[39mcreated\u001b[39m\u001b[39m\"\u001b[39m, msg\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbuilt \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime()\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\s2568\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\phrases.py:648\u001b[0m, in \u001b[0;36mPhrases.add_vocab\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Update model parameters with new `sentences`.\u001b[39;00m\n\u001b[0;32m    615\u001b[0m \n\u001b[0;32m    616\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    641\u001b[0m \n\u001b[0;32m    642\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[39m# Uses a separate vocab to collect the token counts from `sentences`.\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[39m# This consumes more RAM than merging new sentences into `self.vocab`\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[39m# directly, but gives the new sentences a fighting chance to collect\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[39m# sufficient counts, before being pruned out by the (large) accumulated\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[39m# counts collected in previous learn_vocab runs.\u001b[39;00m\n\u001b[1;32m--> 648\u001b[0m min_reduce, vocab, total_words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learn_vocab(\n\u001b[0;32m    649\u001b[0m     sentences, max_vocab_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_vocab_size, delimiter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdelimiter,\n\u001b[0;32m    650\u001b[0m     progress_per\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprogress_per, connector_words\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnector_words,\n\u001b[0;32m    651\u001b[0m )\n\u001b[0;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorpus_word_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m total_words\n\u001b[0;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab:\n",
      "File \u001b[1;32mc:\\Users\\s2568\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\phrases.py:584\u001b[0m, in \u001b[0;36mPhrases._learn_vocab\u001b[1;34m(sentences, max_vocab_size, delimiter, connector_words, progress_per)\u001b[0m\n\u001b[0;32m    582\u001b[0m vocab \u001b[39m=\u001b[39m {}\n\u001b[0;32m    583\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mcollecting all words and their counts\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 584\u001b[0m \u001b[39mfor\u001b[39;00m sentence_no, sentence \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sentences):\n\u001b[0;32m    585\u001b[0m     \u001b[39mif\u001b[39;00m sentence_no \u001b[39m%\u001b[39m progress_per \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    586\u001b[0m         logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    587\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPROGRESS: at sentence #\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m, processed \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m words and \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m word types\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    588\u001b[0m             sentence_no, total_words, \u001b[39mlen\u001b[39m(vocab),\n\u001b[0;32m    589\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\s2568\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\phrases.py:296\u001b[0m, in \u001b[0;36m_PhrasesTransformation.__getitem__\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, sentence):\n\u001b[0;32m    277\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"Convert the input sequence of tokens ``sentence`` into a sequence of tokens where adjacent\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[39m        tokens are replaced by a single token if they form a bigram collocation.\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    294\u001b[0m \n\u001b[0;32m    295\u001b[0m \u001b[39ms        \"\"\"\u001b[39;00m\n\u001b[1;32m--> 296\u001b[0m         is_single, sentence \u001b[39m=\u001b[39m _is_single(sentence)\n\u001b[0;32m    297\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_single:\n\u001b[0;32m    298\u001b[0m             \u001b[39m# If the input is an entire corpus (rather than a single sentence),\u001b[39;00m\n\u001b[0;32m    299\u001b[0m             \u001b[39m# return an iterable stream.\u001b[39;00m\n\u001b[0;32m    300\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(sentence)\n",
      "File \u001b[1;32mc:\\Users\\s2568\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\phrases.py:188\u001b[0m, in \u001b[0;36m_is_single\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_is_single\u001b[39m(obj):\n\u001b[0;32m    171\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check whether `obj` is a single document or an entire corpus.\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \n\u001b[0;32m    173\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \n\u001b[0;32m    187\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m     obj_iter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39;49m(obj)\n\u001b[0;32m    189\u001b[0m     temp_iter \u001b[39m=\u001b[39m obj_iter\n\u001b[0;32m    190\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "sents = metaData['word'].to_list()\n",
    "bigrams = Phrases(sents, min_count=1, threshold=1000)\n",
    "bigram_phrasers = Phrases(bigrams)\n",
    "metaData['word_list_bigrams'] = list(bigram_phrasers[sents])\n",
    "\n",
    "metaData.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
